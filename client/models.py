import sys
import datetime
import requests
from lxml import etree
from sqlalchemy import Column, Integer, String, Sequence, Text, DateTime

from client import app
from database import Base, engine, session

#class Article(Base):
class Article():
    """
    Retrieves the article from the website.
    TODO: Exposes methods for storing article in the database.
    """
    #__tablename__ = "articles"

    # Create instance with Article(slug) => Article("newton")
    # this class will check for the article in the db and render it
    # if it exists, otherwise will fetch it, store the metadata in
    # the db, and then render the article

    """
    id       = Column(Integer, Sequence("post_id_sequence"), primary_key=True)
    title    = Column(String(1024))
    content  = Column(Text)
    datetime = Column(DateTime, default=datetime.datetime.now)
    """

    def __init__(self, url):
        self.url = url

    def fetch(self, url):
        """
        Download and return the HTML page content.
        """
        try:
            page     = requests.get(url)
            response = page.status_code
        except:
            print('Bad connection.')
            print(self)
            sys.exit()

        if response == 200:
            return page
        else:
            print('Bad header response: ' + str(response))
            sys.exit()



class SEP(Article):
    """
    Parses the SEP article content.
    """
    base_url = "http://plato.stanford.edu/entries/"
    xpaths   = {
        "title"     : '//*[@id="aueditable"]/h1/text()',
        "pubdate"   : '//*[@id="pubinfo"]/*/text()',
        "lede"      : '//*[@id="preamble"]/p/text()',
        "toc"       : '//*[@id="toc"]/ul/li/a',
        "text"      : '//*[@id="main-text"]',
        "biblio"    : '//*[@id="bibliography"]',
        "resources" : '//*[@id="other-internet-resources"]',
        "related"   : '//*[@id="related-entries"]',
        "thanks"    : '//*[@id="acknowledgments"]',
    }


    def __init__(self, slug):
        # Setup
        self.url = self.base_url + slug
        app.logger.info("Creating SEP instance: " + self.url)

        # Generate object content
        self.response = self.fetch(self.url)
        self.tree     = etree.HTML(self.response.text)
        self.content  = self.parse()
        app.logger.info(slug + " instance created.")


    def parse(self):
        """
        Parses the HTML tree generated by self.get_tree() into a dictionary of
        the form {<description> : <content>}.
        """
        d = {}
        # TODO: convert to list comprehension
        for k in self.xpaths:
            y = []
            x = self.tree.xpath(self.xpaths[k])
            for i in x:
                if type(i) == etree._Element:
                   y.append(etree.tostring(i))
                else:
                    y.append(i)
            d[k] = y

        return d



#Base.metadata.create_all(engine)
